# Scraping du Blog du ModÃ©rateur

![Logo Blog du ModÃ©rateur](https://www.blogdumoderateur.com/wp-content/themes/bdm/img/logo.svg)

Ce projet est un outil de scraping et de visualisation d'articles du [Blog du ModÃ©rateur](https://www.blogdumoderateur.com/), un site franÃ§ais d'actualitÃ©s sur les mÃ©dias sociaux, le marketing digital et la technologie.

## ğŸ“‹ FonctionnalitÃ©s

### Scraper (`scraper.py`)
- Extraction automatique des articles par catÃ©gorie (Web, Marketing, Social, Tech, Tools)
- Stockage des donnÃ©es dans MongoDB
- RÃ©cupÃ©ration des mÃ©tadonnÃ©es complÃ¨tes:
  - Titre, rÃ©sumÃ©, contenu textuel
  - CatÃ©gorie principale et tags
  - Thumbnail et images
  - Date de publication et auteur
- Multi-threading pour des performances optimisÃ©es
- DÃ©tection des doublons
- Gestion des erreurs et retries

### Frontend (`frontend.py`)
- Interface utilisateur intuitive avec Streamlit
- Filtres avancÃ©s:
  - Recherche par mots-clÃ©s
  - Filtrage par catÃ©gorie, tag, date
- Visualisation au choix:
  - Mode "cartes" avec images et rÃ©sumÃ©s
  - Mode "tableau" pour une vue d'ensemble
- Pagination des rÃ©sultats
- Affichage du contenu complet des articles
- Statistiques sur les donnÃ©es collectÃ©es

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python 3.8+**
- **BeautifulSoup 4** - pour le parsing HTML
- **Requests** - pour les requÃªtes HTTP
- **concurrent.futures** - pour le multi-threading
- **MongoDB** - pour la base de donnÃ©es
- **PyMongo** - pour l'interface avec MongoDB
- **Streamlit** - pour le frontend
- **Pandas** - pour la manipulation de donnÃ©es

## ğŸ’» Installation

1. **Cloner le repository**
   ```bash
   git clone https://github.com/votre-username/scraper-blogdumoderateur.git
   cd scraper-blogdumoderateur
   ```

2. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configurer MongoDB**
   - Installer MongoDB si ce n'est pas dÃ©jÃ  fait
   - S'assurer que MongoDB tourne sur le port 27017 (port par dÃ©faut)

## ğŸš€ Utilisation

### 1. Scraper des articles

```bash
python scraper.py
```

Le script va scraper les 10 premiÃ¨res pages de chaque catÃ©gorie principale et stocker les rÃ©sultats dans MongoDB.

Pour modifier les paramÃ¨tres:
- Nombre de pages: ajuster la variable `max_pages` dans la fonction `scrape_category`
- CatÃ©gories Ã  scraper: modifier la liste `CATEGORIES`

### 2. Lancer le frontend Streamlit

```bash
streamlit run frontend.py
```

L'interface sera accessible Ã  l'adresse http://localhost:8501

## ğŸ“‚ Structure des donnÃ©es MongoDB

Chaque article est stockÃ© avec la structure suivante:

```json
{
  "url": "https://www.blogdumoderateur.com/...",
  "title": "Titre de l'article",
  "thumbnail": "URL de l'image miniature",
  "category": "web|marketing|social|tech|tools",
  "favtag": "Tag principal",
  "tags": ["Tag1", "Tag2", "..."],
  "summary": "RÃ©sumÃ© de l'article",
  "content": "Contenu textuel complet",
  "publication_date": "YYYY-MM-DD",
  "author": "Nom de l'auteur",
  "images": [
    {"url": "URL1", "alt_text": "Texte alternatif", "position": 0},
    {"url": "URL2", "alt_text": "Texte alternatif", "position": 1}
  ],
  "scraped_at": "Date de scraping (ISODate)"
}
```

## âš ï¸ Note lÃ©gale

Ce projet est crÃ©Ã© Ã  des fins Ã©ducatives et de recherche. Veuillez respecter les conditions d'utilisation du Blog du ModÃ©rateur et limiter les requÃªtes pour ne pas surcharger leur serveur. Les donnÃ©es extraites ne doivent pas Ãªtre utilisÃ©es Ã  des fins commerciales sans l'autorisation explicite des propriÃ©taires du site.

## ğŸ“„ Licence

Ce projet est distribuÃ© sous licence MIT. Voir le fichier `LICENSE` pour plus d'informations.

## ğŸ™ Remerciements

- [Blog du ModÃ©rateur](https://www.blogdumoderateur.com/) pour leur contenu de qualitÃ©
- La communautÃ© open-source pour les bibliothÃ¨ques utilisÃ©es

---

ğŸ“Œ **CrÃ©Ã© avec â¤ï¸ par Jyriu** 